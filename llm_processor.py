"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI LLM (GPT-4o-mini)
"""
import json
import logging
import asyncio
import time
from dataclasses import dataclass, asdict
from typing import Optional, List
from datetime import datetime
from openai import OpenAI, OpenAIError

import config
from date_parser import DateParser, extract_priority, normalize_date_for_obsidian

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_RETRIES = 3
BASE_WAIT_TIME = 2  # —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏
MAX_TEXT_LENGTH = 10000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

SYSTEM_PROMPT = """–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–º–µ—Ç–æ–∫ –≤ —Å–∏—Å—Ç–µ–º–µ Personal Knowledge Management (Obsidian).
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –í–†–ï–ú–ï–ù–ù–´–ú –ö–û–ù–¢–ï–ö–°–¢–û–ú.

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ —è–≤–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ
2. –ù–ï –¥–æ–±–∞–≤–ª—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç —Å–µ–±—è
3. –°–û–•–†–ê–ù–Ø–ô –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–∞—Ç –∏ –≤—Ä–µ–º–µ–Ω–∏
4. –¢–µ–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é
5. –†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –Ω–æ –∫—Ä–∞—Ç–∫–∏–º
6. –ó–∞–¥–∞—á–∏ - —Ç–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —É–ø–æ–º—è–Ω—É—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ

–ò–ó–í–õ–ï–ö–ê–ô:
1. –¢–ï–ì–ò (tags): 
   - –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (<30 —Å–ª–æ–≤): 2-3 —Ç–µ–≥–∞
   - –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: 3-5 —Ç–µ–≥–æ–≤
   - –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫, lowercase
   - –§–æ—Ä–º–∞—Ç: kebab-case (—á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å)
   - –û—Ç –æ–±—â–∏—Ö –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
   - –ü—Ä–∏–º–µ—Ä—ã: task, shopping, meeting, health, family, urgent

2. –†–ï–ó–Æ–ú–ï (summary):
   - –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
   - –ú–∞–∫—Å–∏–º—É–º 200 —Å–∏–º–≤–æ–ª–æ–≤
   - –ù–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ —Ç–µ–∫—Å—Ç
   - –§–æ–∫—É—Å –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö –∏–¥–µ—è—Ö

3. –ó–ê–î–ê–ß–ò (action_items):
   - –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏: text, date, time, priority, tags
   - text: –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (–≥–ª–∞–≥–æ–ª + –æ–±—ä–µ–∫—Ç)
   - date: –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD" –∏–ª–∏ null (–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π "today", "tomorrow")
   - time: –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "HH:MM" –∏–ª–∏ null
   - priority: "high", "medium", "low" –∏–ª–∏ null
   - tags: –º–∞—Å—Å–∏–≤ 1-2 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏
   - –ï—Å–ª–∏ –∑–∞–¥–∞—á –Ω–µ—Ç - –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤

–û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–†–ò–û–†–ò–¢–ï–¢–ê:
- high: "—Å—Ä–æ—á–Ω–æ", "–≤–∞–∂–Ω–æ", "ASAP", "–∫—Ä–∏—Ç–∏—á–Ω–æ", "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ"
- medium: –æ–±—ã—á–Ω—ã–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ —è–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
- low: "–∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å", "–Ω–µ —Å–ø–µ—à–Ω–æ", "–ø—Ä–∏ —Å–ª—É—á–∞–µ"

–ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–¢:
- "—Å–µ–≥–æ–¥–Ω—è" ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é reference_date
- "–∑–∞–≤—Ç—Ä–∞" ‚Üí reference_date + 1 –¥–µ–Ω—å
- "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞" ‚Üí reference_date + 2 –¥–Ω—è
- "—á–µ—Ä–µ–∑ N –¥–Ω–µ–π" ‚Üí reference_date + N –¥–Ω–µ–π
- "–≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤–æ –≤—Ç–æ—Ä–Ω–∏–∫" ‚Üí –Ω–∞–π–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–∞–∫–æ–π –¥–µ–Ω—å
- "–Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ" ‚Üí reference_date + 7 –¥–Ω–µ–π
- "DD.MM.YYYY" –∏–ª–∏ "DD.MM" ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π –≤ YYYY-MM-DD

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Å—Ç—Ä–æ–≥–æ JSON):
{
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è",
  "tags": ["tag1", "tag2"],
  "action_items": [
    {
      "text": "–ö—É–ø–∏—Ç—å –º–æ–ª–æ–∫–æ",
      "date": "2026-02-18",
      "time": "10:00",
      "priority": "medium",
      "tags": ["shopping"]
    }
  ]
}

–ü–†–ò–ú–ï–†–´:

–ü—Ä–∏–º–µ—Ä 1 (–∫–æ—Ä–æ—Ç–∫–∞—è –∑–∞–º–µ—Ç–∫–∞):
–í—Ö–æ–¥: "–°—Ö–æ–¥–∏—Ç—å –Ω–∞ –º–∞—Å—Å–∞–∂ –≤ 19:00"
–û—Ç–≤–µ—Ç:
{
  "summary": "–ó–∞–ø–∏—Å—å –Ω–∞ –º–∞—Å—Å–∞–∂ –≤–µ—á–µ—Ä–æ–º",
  "tags": ["health", "self-care"],
  "action_items": [
    {
      "text": "–°—Ö–æ–¥–∏—Ç—å –Ω–∞ –º–∞—Å—Å–∞–∂",
      "date": null,
      "time": "19:00",
      "priority": "medium",
      "tags": ["health"]
    }
  ]
}

–ü—Ä–∏–º–µ—Ä 2 (—Å –¥–∞—Ç–∞–º–∏):
–í—Ö–æ–¥: "–ó–∞–≤—Ç—Ä–∞ –≤ 10:00 –∫—É–ø–∏—Ç—å –º–æ–ª–æ–∫–æ. –°–µ–≥–æ–¥–Ω—è –≤–µ—á–µ—Ä–æ–º –ø–æ–∑–≤–æ–Ω–∏—Ç—å –º–∞–º–µ."
reference_date: "2026-02-17"
–û—Ç–≤–µ—Ç:
{
  "summary": "–°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á: –ø–æ–∫—É–ø–∫–∏ –∏ —Å–µ–º—å—è –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –¥–Ω–∏",
  "tags": ["task", "shopping", "family"],
  "action_items": [
    {
      "text": "–ö—É–ø–∏—Ç—å –º–æ–ª–æ–∫–æ",
      "date": "2026-02-18",
      "time": "10:00",
      "priority": "medium",
      "tags": ["shopping"]
    },
    {
      "text": "–ü–æ–∑–≤–æ–Ω–∏—Ç—å –º–∞–º–µ",
      "date": "2026-02-17",
      "time": "19:00",
      "priority": "medium",
      "tags": ["family"]
    }
  ]
}

–ü—Ä–∏–º–µ—Ä 3 (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã):
–í—Ö–æ–¥: "–°–†–û–ß–ù–û! –û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç –¥–æ –∫–æ–Ω—Ü–∞ –¥–Ω—è"
–û—Ç–≤–µ—Ç:
{
  "summary": "–°—Ä–æ—á–Ω–∞—è –∑–∞–¥–∞—á–∞: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç —Å–µ–≥–æ–¥–Ω—è",
  "tags": ["urgent", "work", "task"],
  "action_items": [
    {
      "text": "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç",
      "date": "2026-02-17",
      "time": null,
      "priority": "high",
      "tags": ["work", "urgent"]
    }
  ]
}

–ù–ï –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫—Ä–æ–º–µ JSON!"""


@dataclass
class ActionItem:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    text: str  # –¢–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
    date: Optional[str] = None  # –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD –∏–ª–∏ "today", "tomorrow"
    time: Optional[str] = None  # –í—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM
    priority: Optional[str] = None  # "high", "medium", "low"
    tags: List[str] = None  # –°–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = []
    
    def to_dict(self) -> dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        return asdict(self)
    
    def to_markdown(self) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ Markdown (–¥–ª—è Obsidian Tasks –ø–ª–∞–≥–∏–Ω–∞)
        
        Returns:
            –°—Ç—Ä–æ–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞: "- [ ] Task üìÖ date ‚è∞ time #tag1 #tag2"
        """
        result = f"- [ ] {self.text}"
        
        if self.date:
            result += f" üìÖ {self.date}"
        
        if self.time:
            result += f" ‚è∞ {self.time}"
        
        if self.tags:
            tags_str = " ".join(f"#{tag}" for tag in self.tags)
            result += f" {tags_str}"
        
        return result


@dataclass
class ProcessingResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM"""
    summary: str
    tags: List[str]
    action_items: List[ActionItem]  # –ò–∑–º–µ–Ω–µ–Ω–æ: —Ç–µ–ø–µ—Ä—å —Å–ø–∏—Å–æ–∫ ActionItem –≤–º–µ—Å—Ç–æ —Å—Ç—Ä–æ–∫
    success: bool
    error_message: Optional[str] = None
    processing_time: float = 0.0
    model_used: str = "gpt-4o-mini"
    dates_mentioned: List[str] = None  # –ù–æ–≤–æ–µ: –≤—Å–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ –¥–∞—Ç—ã
    processing_version: str = "2.0"  # –ù–æ–≤–æ–µ: –≤–µ—Ä—Å–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    def __post_init__(self):
        if self.dates_mentioned is None:
            self.dates_mentioned = []
    
    def to_dict(self) -> dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ dict"""
        return {
            "summary": self.summary,
            "tags": self.tags,
            "action_items": [item.to_dict() for item in self.action_items],
            "success": self.success,
            "error_message": self.error_message,
            "processing_time": self.processing_time,
            "model_used": self.model_used,
            "dates_mentioned": self.dates_mentioned,
            "processing_version": self.processing_version
        }


async def process_text(
    text: str, 
    language: str = "ru",
    client: Optional[OpenAI] = None
) -> ProcessingResult:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ summary –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —è–∑—ã–∫–µ)
        client: OpenAI –∫–ª–∏–µ–Ω—Ç (–µ—Å–ª–∏ None - —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π)
        
    Returns:
        ProcessingResult —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        
    Example:
        >>> result = await process_text("–ó–∞–≤—Ç—Ä–∞ –∫—É–ø–∏—Ç—å –º–æ–ª–æ–∫–æ", "ru")
        >>> result.success
        True
        >>> result.tags
        ['shopping', 'groceries', 'todo']
    """
    start_time = time.time()
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    is_valid, error_msg = validate_text_for_processing(text)
    if not is_valid:
        return ProcessingResult(
            summary="",
            tags=[],
            action_items=[],
            success=False,
            error_message=error_msg
        )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
    if client is None:
        if not config.OPENAI_API_KEY:
            return ProcessingResult(
                summary="",
                tags=[],
                action_items=[],
                success=False,
                error_message="OPENAI_API_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
            )
        client = OpenAI(api_key=config.OPENAI_API_KEY)
    
    # –í—ã–∑–æ–≤ LLM —Å retry
    try:
        reference_date = datetime.now()
        response_data = await _call_llm_with_retry(client, text, language, reference_date)
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        if not _validate_response(response_data):
            return ProcessingResult(
                summary="",
                tags=[],
                action_items=[],
                success=False,
                error_message="LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
            )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è action_items –∏–∑ dict –≤ ActionItem –æ–±—ä–µ–∫—Ç—ã
        action_items = []
        dates_mentioned = []
        
        for item_data in response_data.get("action_items", []):
            # –ü–∞—Ä—Å–∏–Ω–≥ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç—ã
            date = item_data.get("date")
            if date:
                dates_mentioned.append(date)
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è Obsidian (today/tomorrow)
                date = normalize_date_for_obsidian(date, reference_date)
            
            action_item = ActionItem(
                text=item_data.get("text", ""),
                date=date,
                time=item_data.get("time"),
                priority=item_data.get("priority"),
                tags=item_data.get("tags", [])
            )
            action_items.append(action_item)
        
        processing_time = time.time() - start_time
        
        return ProcessingResult(
            summary=response_data.get("summary", ""),
            tags=response_data.get("tags", []),
            action_items=action_items,
            success=True,
            processing_time=processing_time,
            model_used=config.SMART_PROCESSING_MODEL,
            dates_mentioned=sorted(list(set(dates_mentioned))),
            processing_version="2.0"
        )
        
    except Exception as e:
        logger.error(f"Unexpected error in process_text: {e}", exc_info=True)
        return ProcessingResult(
            summary="",
            tags=[],
            action_items=[],
            success=False,
            error_message=f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
        )


async def _call_llm_with_retry(
    client: OpenAI,
    text: str,
    language: str,
    reference_date: Optional[datetime] = None
) -> dict:
    """
    –í—ã–∑–æ–≤ LLM —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    
    Implements exponential backoff: wait_time = 2^attempt seconds
    
    Args:
        client: OpenAI –∫–ª–∏–µ–Ω—Ç
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞
        
    Returns:
        dict —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (summary, tags, action_items)
        
    Raises:
        Exception: –ü–æ—Å–ª–µ MAX_RETRIES –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
    """
    last_error = None
    
    for attempt in range(MAX_RETRIES):
        try:
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            user_prompt = _create_user_prompt(text, language, reference_date)
            
            # –í—ã–∑–æ–≤ OpenAI API
            response = client.chat.completions.create(
                model=config.SMART_PROCESSING_MODEL,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=config.SMART_PROCESSING_TEMPERATURE,
                max_tokens=config.SMART_PROCESSING_MAX_TOKENS,
                response_format={"type": "json_object"}  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç JSON
            )
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
            response_text = response.choices[0].message.content
            response_data = _parse_llm_response(response_text)
            
            logger.info(
                f"LLM processing successful on attempt {attempt + 1}",
                extra={"text_length": len(text), "model": config.SMART_PROCESSING_MODEL}
            )
            
            return response_data
            
        except OpenAIError as e:
            last_error = e
            logger.warning(f"OpenAI API error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")
            
            if attempt < MAX_RETRIES - 1:
                wait_time = BASE_WAIT_TIME ** attempt
                logger.info(f"Retrying in {wait_time}s...")
                await asyncio.sleep(wait_time)
        
        except Exception as e:
            last_error = e
            logger.error(f"Unexpected error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")
            
            if attempt < MAX_RETRIES - 1:
                wait_time = BASE_WAIT_TIME ** attempt
                await asyncio.sleep(wait_time)
    
    # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
    error_msg = f"LLM processing failed after {MAX_RETRIES} attempts: {str(last_error)}"
    logger.error(error_msg)
    raise Exception(error_msg)


def _create_user_prompt(text: str, language: str, reference_date: Optional[datetime] = None) -> str:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ user prompt –¥–ª—è LLM
    
    Args:
        text: –¢–µ–∫—Å—Ç –∑–∞–º–µ—Ç–∫–∏
        language: –ö–æ–¥ —è–∑—ã–∫–∞ (ru, en, uk, etc.)
        reference_date: –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç
        
    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    """
    language_names = {
        "ru": "—Ä—É—Å—Å–∫–∏–π",
        "en": "–∞–Ω–≥–ª–∏–π—Å–∫–∏–π",
        "uk": "—É–∫—Ä–∞–∏–Ω—Å–∫–∏–π",
        "de": "–Ω–µ–º–µ—Ü–∫–∏–π",
        "fr": "—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π",
        "es": "–∏—Å–ø–∞–Ω—Å–∫–∏–π",
        "it": "–∏—Ç–∞–ª—å—è–Ω—Å–∫–∏–π",
        "pt": "–ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π"
    }
    
    lang_name = language_names.get(language, "–∏—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞")
    
    if not reference_date:
        reference_date = datetime.now()
    
    ref_date_str = reference_date.strftime("%Y-%m-%d")
    
    return f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

–¢–ï–ö–°–¢:
{text}

–ö–û–ù–¢–ï–ö–°–¢:
- reference_date: {ref_date_str} (–∏—Å–ø–æ–ª—å–∑—É–π –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ "—Å–µ–≥–æ–¥–Ω—è", "–∑–∞–≤—Ç—Ä–∞", etc.)
- –Ø–∑—ã–∫ —Ä–µ–∑—é–º–µ: {lang_name}
- –¢–µ–≥–∏: –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, lowercase, kebab-case
- –ó–∞–¥–∞—á–∏: –∏–∑–≤–ª–µ–∫–∞–π text, date, time, priority, tags

–í–ê–ñ–ù–û:
- –°–æ—Ö—Ä–∞–Ω—è–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
- –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞—Ç—ã ("–∑–∞–≤—Ç—Ä–∞", "—á–µ—Ä–µ–∑ 2 –¥–Ω—è") –≤ YYYY-MM-DD —Ñ–æ—Ä–º–∞—Ç
- –ò–∑–≤–ª–µ–∫–∞–π –≤—Ä–µ–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON."""


def _parse_llm_response(response: str) -> dict:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ LLM –¥–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON
    
    Args:
        response: –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM
        
    Returns:
        –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π dict
        
    Raises:
        json.JSONDecodeError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        return json.loads(response)
    except json.JSONDecodeError:
        # –ü–æ–∏—Å–∫ JSON –≤ —Ç–µ–∫—Å—Ç–µ
        json_start = response.find('{')
        json_end = response.rfind('}') + 1
        
        if json_start == -1 or json_end == 0:
            raise json.JSONDecodeError("No JSON found in response", response, 0)
        
        json_str = response[json_start:json_end]
        return json.loads(json_str)


def _validate_response(response_data: dict) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM
    
    Args:
        response_data: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        
    Returns:
        True –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤–∞–ª–∏–¥–Ω–∞
    """
    required_keys = {"summary", "tags", "action_items"}
    
    if not all(key in response_data for key in required_keys):
        return False
    
    if not isinstance(response_data["summary"], str):
        return False
    
    if not isinstance(response_data["tags"], list):
        return False
    
    if not isinstance(response_data["action_items"], list):
        return False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ä–µ–∑—é–º–µ
    if len(response_data["summary"]) > 250:  # 200 + –±—É—Ñ–µ—Ä
        response_data["summary"] = response_data["summary"][:200]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–≥–æ–≤ (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç—Ä–æ–∫–∞–º–∏, lowercase, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤)
    response_data["tags"] = [
        tag.lower().replace(" ", "-") 
        for tag in response_data["tags"] 
        if isinstance(tag, str)
    ][:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —Ç–µ–≥–æ–≤
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è action_items (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å dict —Å –ø–æ–ª–µ–º text)
    valid_action_items = []
    for item in response_data["action_items"]:
        if isinstance(item, dict) and "text" in item:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª–µ–π ActionItem
            validated_item = {
                "text": str(item.get("text", "")),
                "date": item.get("date") if item.get("date") else None,
                "time": item.get("time") if item.get("time") else None,
                "priority": item.get("priority") if item.get("priority") in ["high", "medium", "low"] else None,
                "tags": [tag.lower().replace(" ", "-") for tag in item.get("tags", []) if isinstance(tag, str)][:2]
            }
            valid_action_items.append(validated_item)
    
    response_data["action_items"] = valid_action_items
    
    return True


def validate_text_for_processing(text: str) -> tuple[bool, str]:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ LLM
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        tuple: (is_valid, error_message)
    """
    if not text or not text.strip():
        return False, "–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç"
    
    if len(text) > MAX_TEXT_LENGTH:
        return False, f"–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å {MAX_TEXT_LENGTH} —Å–∏–º–≤–æ–ª–æ–≤)"
    
    return True, "OK"
